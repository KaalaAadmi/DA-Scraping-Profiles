{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOT REQUIRED:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_driver = os.getcwd()+\"\\\\chromedriver\\\\chromedriver.exe\"\n",
    "print(chrome_driver)\n",
    "# Path to your chrome profile\n",
    "chrome_options.add_argument(\n",
    "    \"user-data-dir=C:\\\\Users\\\\Arnav\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")\n",
    "# chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(\n",
    "    options=chrome_options, executable_path=chrome_driver)\n",
    "driver.maximize_window()\n",
    "\n",
    "driver.get(\"https://www.linkedin.com/feed/update/urn:li:activity:7018371251677138944?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7018371251677138944%2C7018425801251389440%29&dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287018425801251389440%2Curn%3Ali%3Aactivity%3A7018371251677138944%29\")\n",
    "time.sleep(2)\n",
    "reactions=driver.find_element_by_xpath(\"/html/body/div[5]/div[3]/div/div/div/div[2]/div/div/main/div/section/div/div/div[6]/div[3]/div[3]/div[1]/article[1]/div[4]/div[2]/div/div[1]/button/span\").click()\n",
    "time.sleep(2)\n",
    "# likes=driver.find_element_by_xpath(\"/html/body/div[3]/div/div/div[1]/div/div[1]/div/button[2]/div\").click()\n",
    "# time.sleep(2)\n",
    "total_likes=driver.find_element_by_xpath(\"/html/body/div[3]/div/div/div[1]/div/div[1]/div/button[1]/div/span[2]\").text\n",
    "total_likes=int(total_likes)\n",
    "print(total_likes)\n",
    "people=[]\n",
    "reactions=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "container = driver.find_element_by_xpath(\"/html/body/div[3]/div/div/div[2]\")\n",
    "\n",
    "num = total_likes//10\n",
    "for i in range(0, num):\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\n",
    "        \"arguments[0].scrollTop = arguments[0].scrollHeight\", container)\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "for j in range(1, total_likes+1):\n",
    "    try:\n",
    "        container = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[3]/div/div/div[2]\")\n",
    "        react = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[3]/div/div/div[2]/div/div/div[1]/ul/li[\"+str(i)+\"]/div/div/a/div/div[1]/div/img\").get_attribute('alt')\n",
    "        person = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[3]/div/div/div[2]/div/div/div[1]/ul/li[\"+str(i)+\"]/div/div/a/div/div[2]/div[1]/span[1]/span\").text\n",
    "        people.append(person)\n",
    "        reactions.append(react)\n",
    "    except NoSuchElementException:\n",
    "        print(\"No such element found at \"+str(i)+\"th position\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'People': people, 'Reactions': reactions}\n",
    "\n",
    "# Create a dataframe from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('reactions1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /html/body/div[3]/div/div/div[2]/div/div/div[1]/ul/li[698]/div/div/a\n",
    "# /html/body/div[3]/div/div/div[2]/div/div/div[1]/ul/li[701]/div/div/a\n",
    "i = 1\n",
    "profile = []\n",
    "for j in range(1, total_likes+1):\n",
    "    try:\n",
    "        p = driver.find_element_by_xpath(\"/html/body/div[3]/div/div/div[2]/div/div/div[1]/ul/li[\"+str(i)+\"]/div/div/a\").get_attribute('href')\n",
    "        profile.append(p)\n",
    "    except NoSuchElementException:\n",
    "        print(\"No such element found at \"+str(i)+\"th position\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "profile=[]\n",
    "for j in range(1, total_likes+1):\n",
    "    try:\n",
    "        # print(i)\n",
    "        p=driver.find_element_by_xpath(\"/html/body/div[3]/div/div/div[2]/div/div/div[1]/ul/li[\"+str(i)+\"]/div/div/a/div/div[2]/div[1]/span[1]/span\").click()\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        time.sleep(10)\n",
    "        val=driver.current_url\n",
    "        # print(str(val))\n",
    "        profile.append(val)\n",
    "        # driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + 'w')\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        print(\"No such element found at \"+str(i)+\"th position\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(people))\n",
    "print(len(reactions))\n",
    "print(len(profile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {\"Profile\":profile}\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "df1.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16204\\1215531590.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmerged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombine_first\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmerged\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'merged.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "merged = df.combine_first(df1)\n",
    "merged.to_csv('merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define a list of proxy servers\n",
    "proxies = [\n",
    "    {'http': 'http://1.1.1.1:8080', 'https': 'https://1.1.1.1:8080'},\n",
    "    {'http': 'http://2.2.2.2:8080', 'https': 'https://2.2.2.2:8080'},\n",
    "    {'http': 'http://3.3.3.3:8080', 'https': 'https://3.3.3.3:8080'}\n",
    "]\n",
    "\n",
    "# Loop through the list of proxies and send a request using each one\n",
    "for proxy in proxies:\n",
    "    try:\n",
    "        response = requests.get('http://example.com', proxies=proxy)\n",
    "        print(response.content)\n",
    "    except:\n",
    "        print(\"Connection error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllib2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>People</th>\n",
       "      <th>Profile</th>\n",
       "      <th>Reactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Pawel Czarczynski</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAABPhLisBO84-X7...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Heather Wylie</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAAAANe6cBu5F-0i...</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tanika Berry B.S.,CRCR, CPAR</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAAB-Yc0IB7BKFA9...</td>\n",
       "      <td>celebrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Camoih Scott</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAABQJbb4BebujHU...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aijamal Jusupova</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAAAHT38IBU_xYSH...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>628</td>\n",
       "      <td>Jovana Rakic</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAAARyI3QBwivpJX...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>629</td>\n",
       "      <td>Nazlı Vasilev</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAAAcPXckBmFzZR1...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>630</td>\n",
       "      <td>Piyali Das</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAADannvIBTGktGm...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>631</td>\n",
       "      <td>Anna Van Vuuren</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAABXNyjkBaGbsC-...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>632</td>\n",
       "      <td>Lilia A.</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAABd1GS4Bcuumui...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                        People  \\\n",
       "0             0             Pawel Czarczynski   \n",
       "1             1                 Heather Wylie   \n",
       "2             2  Tanika Berry B.S.,CRCR, CPAR   \n",
       "3             3                  Camoih Scott   \n",
       "4             4              Aijamal Jusupova   \n",
       "..          ...                           ...   \n",
       "628         628                  Jovana Rakic   \n",
       "629         629                 Nazlı Vasilev   \n",
       "630         630                    Piyali Das   \n",
       "631         631               Anna Van Vuuren   \n",
       "632         632                      Lilia A.   \n",
       "\n",
       "                                               Profile  Reactions  \n",
       "0    https://www.linkedin.com/in/ACoAABPhLisBO84-X7...       like  \n",
       "1    https://www.linkedin.com/in/ACoAAAANe6cBu5F-0i...      funny  \n",
       "2    https://www.linkedin.com/in/ACoAAB-Yc0IB7BKFA9...  celebrate  \n",
       "3    https://www.linkedin.com/in/ACoAABQJbb4BebujHU...       like  \n",
       "4    https://www.linkedin.com/in/ACoAAAHT38IBU_xYSH...       like  \n",
       "..                                                 ...        ...  \n",
       "628  https://www.linkedin.com/in/ACoAAARyI3QBwivpJX...       like  \n",
       "629  https://www.linkedin.com/in/ACoAAAcPXckBmFzZR1...       like  \n",
       "630  https://www.linkedin.com/in/ACoAADannvIBTGktGm...       like  \n",
       "631  https://www.linkedin.com/in/ACoAABXNyjkBaGbsC-...       like  \n",
       "632  https://www.linkedin.com/in/ACoAABd1GS4Bcuumui...       like  \n",
       "\n",
       "[633 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reaction_df=pd.read_csv('merged.csv')\n",
    "reaction_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOT REQUIRED:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_driver = os.getcwd()+\"\\\\chromedriver\\\\chromedriver.exe\"\n",
    "print(chrome_driver)\n",
    "# Path to your chrome profile\n",
    "chrome_options.add_argument(\n",
    "    \"user-data-dir=C:\\\\Users\\\\Arnav\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")\n",
    "# chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(\n",
    "    options=chrome_options, executable_path=chrome_driver)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_driver = os.getcwd()+\"\\\\chromedriver\\\\chromedriver.exe\"\n",
    "print(chrome_driver)\n",
    "# Path to your chrome profile\n",
    "chrome_options.add_argument(\n",
    "    \"user-data-dir=C:\\\\Users\\\\Arnav\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")\n",
    "# chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(\n",
    "    options=chrome_options, executable_path=chrome_driver)\n",
    "driver.maximize_window()\n",
    "profiles=reaction_df['Profile']\n",
    "experience=[]\n",
    "i=0\n",
    "for profile in profiles:\n",
    "    if i>0:\n",
    "        break;\n",
    "    url=profile+\"/details/experience/\"\n",
    "    driver.get(url)\n",
    "    # driver.get(profile)\n",
    "    time.sleep(5)\n",
    "    get_url = driver.current_url\n",
    "    new_url=get_url+\"/details/experience/\"\n",
    "    driver.get(new_url)\n",
    "    # exp=driver.find_element_by_xpath(\"/html/body/div[5]/div[3]/div/div/div[2]/div/div/main/section\")\n",
    "    time.sleep(10)\n",
    "    pageSource = driver.page_source\n",
    "    print(pageSource)\n",
    "    i+=1\n",
    "    # page = urllib2.urlopen(url)\n",
    "    # soup = BeautifulSoup(page, 'html.parser')\n",
    "    # print(soup)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\TCD\\Data Analytics\\Project\\chromedriver\\chromedriver.exe\n",
      "Teladoc Health\n",
      "Product Lead\n",
      "Sr. Manager, Technical Program Management - Solutions Delivery\n",
      "Sr. Manager, Corporate Applications and Support\n",
      "Manager, Corporate Applications & Business Support\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import os\n",
    "import time\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_driver = os.getcwd()+\"\\\\chromedriver\\\\chromedriver.exe\"\n",
    "print(chrome_driver)\n",
    "# Path to your chrome profile\n",
    "chrome_options.add_argument(\n",
    "    \"user-data-dir=C:\\\\Users\\\\Arnav\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")\n",
    "# chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(\n",
    "    options=chrome_options, executable_path=chrome_driver)\n",
    "driver.maximize_window()\n",
    "\n",
    "profiles = reaction_df['Profile']\n",
    "profile_data = {}\n",
    "i=1\n",
    "current_comp=\"\"\n",
    "current_location=\"\"\n",
    "current_pos=\"\"\n",
    "num=int(input(\"Enter the number of profiles you want to scrape from: \"))\n",
    "end=int(input(\"Enter the number of profiles you want to scrape till: \"))\n",
    "# for profile in profiles:\n",
    "for i in range(0,num):\n",
    "    if i > end:\n",
    "        break\n",
    "\n",
    "    driver.get(profile)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        current_pos = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[5]/div[3]/div/div/div[2]/div/div/main/section[1]/div[2]/div[2]/div[1]/div[2]\").text\n",
    "        current_comp = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[5]/div[3]/div/div/div[2]/div/div/main/section[1]/div[2]/div[2]/ul/li/button/span/div\").text\n",
    "        current_location = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[5]/div[3]/div/div/div[2]/div/div/main/section[1]/div[2]/div[2]/div[2]/span[1]\").text\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    get_url = driver.current_url\n",
    "    new_url = get_url+\"/details/experience/\"\n",
    "    driver.get(new_url)\n",
    "    time.sleep(10)\n",
    "    j = 1\n",
    "    experiences = []\n",
    "    while True:\n",
    "        try:\n",
    "            position = driver.find_element_by_xpath(\n",
    "                \"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[\"+str(j)+\"]/div/div/div[2]/div[1]/div[1]/div/span/span[1]\").text\n",
    "            comp_name = driver.find_element_by_xpath(\n",
    "                \"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[\"+str(j)+\"]/div/div/div[2]/div[1]/div[1]/span[1]/span[1]\").text\n",
    "            exp = driver.find_element_by_xpath(\n",
    "                \"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[\"+str(j)+\"]/div/div/div[2]/div[1]/div[1]/span[2]/span[1]\").text\n",
    "            experiences.append(\n",
    "                {'Position': position, 'Company': comp_name, 'Experience': exp})\n",
    "            j += 1\n",
    "        except NoSuchElementException:\n",
    "            l=1\n",
    "            # while True:\n",
    "            try:\n",
    "                comp=driver.find_element_by_xpath(\"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[\"+str(l)+\"]/div/div/div[2]/div[1]/a/div/span/span[1]\").text\n",
    "                total_exp=driver.find_element_by_xpath(\"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[1]/div/div/div[2]/div[1]/a/span/span[1]\").text\n",
    "                print(comp)\n",
    "                k=1\n",
    "                while True:\n",
    "                    try:\n",
    "                        post=driver.find_element_by_xpath(\"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[1]/div/div/div[2]/div[2]/ul/li/div/div/div[1]/ul/li[\"+str(k)+\"]/div/div/div[2]/div[1]/a/div/span/span[1]\").text\n",
    "                        print(post)\n",
    "                        experiences.append(\n",
    "                            {'Position': post, 'Company': comp, 'Experience': total_exp})\n",
    "                        k+=1\n",
    "                    except NoSuchElementException:\n",
    "                        break\n",
    "                l+=1\n",
    "            except NoSuchElementException:\n",
    "                break\n",
    "            break\n",
    "    profile_data[profile] = {'Experiences': experiences,\n",
    "                         'Current Position': current_pos,\n",
    "                         'Current Company': current_comp,\n",
    "                         'Current Location': current_location}\n",
    "\n",
    "    i += 1\n",
    "\n",
    "# Save data to CSV file\n",
    "with open('output.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Profile\", \"Position\", \"Company\", \"Experience\", \"Current_Position\", \"Current_Company\", \"Current_Location\"])\n",
    "    for profile, experiences in profile_data.items():\n",
    "        flattened_data = [{'Profile': profile,\n",
    "                            'Position': exp['Position'],\n",
    "                            'Company': exp['Company'],\n",
    "                            'Experience': exp['Experience'],\n",
    "                            'Current Position': experiences['Current Position'],\n",
    "                            'Current Company': experiences['Current Company'],\n",
    "                            'Current Location': experiences['Current Location']}\n",
    "                            for exp in experiences['Experiences']]\n",
    "\n",
    "        for data in flattened_data:\n",
    "            writer.writerow(data.values())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
