{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_driver = os.getcwd()+\"\\\\chromedriver\\\\chromedriver.exe\"\n",
    "print(chrome_driver)\n",
    "# Path to your chrome profile\n",
    "chrome_options.add_argument(\n",
    "    \"user-data-dir=C:\\\\Users\\\\Arnav\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")\n",
    "# chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(\n",
    "    options=chrome_options, executable_path=chrome_driver)\n",
    "driver.maximize_window()\n",
    "\n",
    "driver.get(\"https://www.linkedin.com/feed/update/urn:li:activity:7018371251677138944?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7018371251677138944%2C7018425801251389440%29&dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287018425801251389440%2Curn%3Ali%3Aactivity%3A7018371251677138944%29\")\n",
    "time.sleep(2)\n",
    "reactions=driver.find_element_by_xpath(\"/html/body/div[5]/div[3]/div/div/div/div[2]/div/div/main/div/section/div/div/div[6]/div[3]/div[3]/div[1]/article[1]/div[4]/div[2]/div/div[1]/button/span\").click()\n",
    "time.sleep(2)\n",
    "# likes=driver.find_element_by_xpath(\"/html/body/div[3]/div/div/div[1]/div/div[1]/div/button[2]/div\").click()\n",
    "# time.sleep(2)\n",
    "total_likes=driver.find_element_by_xpath(\"/html/body/div[3]/div/div/div[1]/div/div[1]/div/button[1]/div/span[2]\").text\n",
    "total_likes=int(total_likes)\n",
    "print(total_likes)\n",
    "people=[]\n",
    "reactions=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "container = driver.find_element_by_xpath(\"/html/body/div[3]/div/div/div[2]\")\n",
    "\n",
    "num = total_likes//10\n",
    "for i in range(0, num):\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\n",
    "        \"arguments[0].scrollTop = arguments[0].scrollHeight\", container)\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "for j in range(1, total_likes+1):\n",
    "    try:\n",
    "        container = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[3]/div/div/div[2]\")\n",
    "        react = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[3]/div/div/div[2]/div/div/div[1]/ul/li[\"+str(i)+\"]/div/div/a/div/div[1]/div/img\").get_attribute('alt')\n",
    "        person = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[3]/div/div/div[2]/div/div/div[1]/ul/li[\"+str(i)+\"]/div/div/a/div/div[2]/div[1]/span[1]/span\").text\n",
    "        people.append(person)\n",
    "        reactions.append(react)\n",
    "    except NoSuchElementException:\n",
    "        print(\"No such element found at \"+str(i)+\"th position\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'People': people, 'Reactions': reactions}\n",
    "\n",
    "# Create a dataframe from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('reactions1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /html/body/div[3]/div/div/div[2]/div/div/div[1]/ul/li[698]/div/div/a\n",
    "# /html/body/div[3]/div/div/div[2]/div/div/div[1]/ul/li[701]/div/div/a\n",
    "i = 1\n",
    "profile = []\n",
    "for j in range(1, total_likes+1):\n",
    "    try:\n",
    "        p = driver.find_element_by_xpath(\"/html/body/div[3]/div/div/div[2]/div/div/div[1]/ul/li[\"+str(i)+\"]/div/div/a\").get_attribute('href')\n",
    "        profile.append(p)\n",
    "    except NoSuchElementException:\n",
    "        print(\"No such element found at \"+str(i)+\"th position\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "profile=[]\n",
    "for j in range(1, total_likes+1):\n",
    "    try:\n",
    "        # print(i)\n",
    "        p=driver.find_element_by_xpath(\"/html/body/div[3]/div/div/div[2]/div/div/div[1]/ul/li[\"+str(i)+\"]/div/div/a/div/div[2]/div[1]/span[1]/span\").click()\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        time.sleep(10)\n",
    "        val=driver.current_url\n",
    "        # print(str(val))\n",
    "        profile.append(val)\n",
    "        # driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + 'w')\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        print(\"No such element found at \"+str(i)+\"th position\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(people))\n",
    "print(len(reactions))\n",
    "print(len(profile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {\"Profile\":profile}\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "df1.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = df.combine_first(df1)\n",
    "merged.to_csv('merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define a list of proxy servers\n",
    "proxies = [\n",
    "    {'http': 'http://1.1.1.1:8080', 'https': 'https://1.1.1.1:8080'},\n",
    "    {'http': 'http://2.2.2.2:8080', 'https': 'https://2.2.2.2:8080'},\n",
    "    {'http': 'http://3.3.3.3:8080', 'https': 'https://3.3.3.3:8080'}\n",
    "]\n",
    "\n",
    "# Loop through the list of proxies and send a request using each one\n",
    "for proxy in proxies:\n",
    "    try:\n",
    "        response = requests.get('http://example.com', proxies=proxy)\n",
    "        print(response.content)\n",
    "    except:\n",
    "        print(\"Connection error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>People</th>\n",
       "      <th>Profile</th>\n",
       "      <th>Reactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Pawel Czarczynski</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAABPhLisBO84-X7...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Heather Wylie</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAAAANe6cBu5F-0i...</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tanika Berry B.S.,CRCR, CPAR</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAAB-Yc0IB7BKFA9...</td>\n",
       "      <td>celebrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Camoih Scott</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAABQJbb4BebujHU...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aijamal Jusupova</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAAAHT38IBU_xYSH...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>628</td>\n",
       "      <td>Jovana Rakic</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAAARyI3QBwivpJX...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>629</td>\n",
       "      <td>Nazlı Vasilev</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAAAcPXckBmFzZR1...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>630</td>\n",
       "      <td>Piyali Das</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAADannvIBTGktGm...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>631</td>\n",
       "      <td>Anna Van Vuuren</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAABXNyjkBaGbsC-...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>632</td>\n",
       "      <td>Lilia A.</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAABd1GS4Bcuumui...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                        People  \\\n",
       "0             0             Pawel Czarczynski   \n",
       "1             1                 Heather Wylie   \n",
       "2             2  Tanika Berry B.S.,CRCR, CPAR   \n",
       "3             3                  Camoih Scott   \n",
       "4             4              Aijamal Jusupova   \n",
       "..          ...                           ...   \n",
       "628         628                  Jovana Rakic   \n",
       "629         629                 Nazlı Vasilev   \n",
       "630         630                    Piyali Das   \n",
       "631         631               Anna Van Vuuren   \n",
       "632         632                      Lilia A.   \n",
       "\n",
       "                                               Profile  Reactions  \n",
       "0    https://www.linkedin.com/in/ACoAABPhLisBO84-X7...       like  \n",
       "1    https://www.linkedin.com/in/ACoAAAANe6cBu5F-0i...      funny  \n",
       "2    https://www.linkedin.com/in/ACoAAB-Yc0IB7BKFA9...  celebrate  \n",
       "3    https://www.linkedin.com/in/ACoAABQJbb4BebujHU...       like  \n",
       "4    https://www.linkedin.com/in/ACoAAAHT38IBU_xYSH...       like  \n",
       "..                                                 ...        ...  \n",
       "628  https://www.linkedin.com/in/ACoAAARyI3QBwivpJX...       like  \n",
       "629  https://www.linkedin.com/in/ACoAAAcPXckBmFzZR1...       like  \n",
       "630  https://www.linkedin.com/in/ACoAADannvIBTGktGm...       like  \n",
       "631  https://www.linkedin.com/in/ACoAABXNyjkBaGbsC-...       like  \n",
       "632  https://www.linkedin.com/in/ACoAABd1GS4Bcuumui...       like  \n",
       "\n",
       "[633 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reaction_df=pd.read_csv('merged.csv')\n",
    "reaction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_driver = os.getcwd()+\"\\\\chromedriver\\\\chromedriver.exe\"\n",
    "print(chrome_driver)\n",
    "# Path to your chrome profile\n",
    "chrome_options.add_argument(\n",
    "    \"user-data-dir=C:\\\\Users\\\\Arnav\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")\n",
    "# chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(\n",
    "    options=chrome_options, executable_path=chrome_driver)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_driver = os.getcwd()+\"\\\\chromedriver\\\\chromedriver.exe\"\n",
    "print(chrome_driver)\n",
    "# Path to your chrome profile\n",
    "chrome_options.add_argument(\n",
    "    \"user-data-dir=C:\\\\Users\\\\Arnav\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")\n",
    "# chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(\n",
    "    options=chrome_options, executable_path=chrome_driver)\n",
    "driver.maximize_window()\n",
    "profiles=reaction_df['Profile']\n",
    "experience=[]\n",
    "i=0\n",
    "for profile in profiles:\n",
    "    if i>0:\n",
    "        break;\n",
    "    url=profile+\"/details/experience/\"\n",
    "    driver.get(url)\n",
    "    # driver.get(profile)\n",
    "    time.sleep(5)\n",
    "    get_url = driver.current_url\n",
    "    new_url=get_url+\"/details/experience/\"\n",
    "    driver.get(new_url)\n",
    "    # exp=driver.find_element_by_xpath(\"/html/body/div[5]/div[3]/div/div/div[2]/div/div/main/section\")\n",
    "    time.sleep(10)\n",
    "    pageSource = driver.page_source\n",
    "    print(pageSource)\n",
    "    i+=1\n",
    "    # page = urllib2.urlopen(url)\n",
    "    # soup = BeautifulSoup(page, 'html.parser')\n",
    "    # print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\TCD\\Data Analytics\\chromedriver\\chromedriver.exe\n",
      "No such element found at 1th position\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3084\\2968496872.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mnew_url\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_url\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/details/experience/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chrome_options = Options()\n",
    "chrome_driver = os.getcwd()+\"\\\\chromedriver\\\\chromedriver.exe\"\n",
    "print(chrome_driver)\n",
    "# Path to your chrome profile\n",
    "chrome_options.add_argument(\n",
    "    \"user-data-dir=C:\\\\Users\\\\Arnav\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")\n",
    "# chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(\n",
    "    options=chrome_options, executable_path=chrome_driver)\n",
    "driver.maximize_window()\n",
    "profiles=reaction_df['Profile']\n",
    "experience=[]\n",
    "i=1\n",
    "for profile in profiles:\n",
    "    if i>5:\n",
    "        break;\n",
    "\n",
    "    driver.get(profile)\n",
    "    time.sleep(5)\n",
    "    get_url = driver.current_url\n",
    "    new_url=get_url+\"/details/experience/\"\n",
    "    driver.get(new_url)\n",
    "    time.sleep(10)\n",
    "    j=1\n",
    "    while True:\n",
    "        try:\n",
    "            position=driver.find_element_by_xpath(\"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[\"+str(j)+\"]/div/div/div[2]/div[1]/div[1]/div/span/span[1]\").text\n",
    "            comp_name=driver.find_element_by_xpath(\"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[\"+str(j)+\"]/div/div/div[2]/div[1]/div[1]/span[1]/span[1]\").text\n",
    "            exp=driver.find_element_by_xpath(\"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[\"+str(j)+\"]/div/div/div[2]/div[1]/div[1]/span[2]/span[1]\").text\n",
    "            print(f\"Position: {position}\")\n",
    "            print(f\"Company: {comp_name}\")\n",
    "            print(f\"Experience: {exp}\")\n",
    "            j+=1\n",
    "        except NoSuchElementException:\n",
    "            print(\"No such element found at \"+str(j)+\"th position\")\n",
    "            break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\TCD\\Data Analytics\\chromedriver\\chromedriver.exe\n",
      "Position: Rotating Equipment Engineer\n",
      "Company: Schlumberger · Full-time\n",
      "Experience: Aug 2022 - Present · 10 mos\n",
      "Position: Rotating Equipment Engineer\n",
      "Company: L & T Chiyoda Ltd · Full-time\n",
      "Experience: Feb 2018 - Jul 2022 · 4 yrs 6 mos\n",
      "Position: Mechanical Engineer\n",
      "Company: Venus engineering and consultancy · Full-time\n",
      "Experience: Aug 2016 - Jan 2018 · 1 yr 6 mos\n",
      "Position: Rotating Equipment Engineer\n",
      "Company: Fluor Daniel India Private Limited\n",
      "Experience: Feb 2015 - May 2016 · 1 yr 4 mos\n",
      "Position: Rotating Equipment Engineer\n",
      "Company: GS E&C\n",
      "Experience: Feb 2014 - Feb 2015 · 1 yr 1 mo\n",
      "Position: Rotating Equipment Engineer\n",
      "Company: IOTL\n",
      "Experience: Aug 2011 - Dec 2013 · 2 yrs 5 mos\n",
      "No such element found at 7th position\n",
      "No such element found at 1th position\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import os\n",
    "import time\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_driver = os.getcwd()+\"\\\\chromedriver\\\\chromedriver.exe\"\n",
    "print(chrome_driver)\n",
    "# Path to your chrome profile\n",
    "chrome_options.add_argument(\n",
    "    \"user-data-dir=C:\\\\Users\\\\Arnav\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")\n",
    "# chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(\n",
    "    options=chrome_options, executable_path=chrome_driver)\n",
    "driver.maximize_window()\n",
    "\n",
    "profiles = reaction_df['Profile']\n",
    "profile_data = {}\n",
    "\n",
    "for profile in profiles:\n",
    "    if i > 2:\n",
    "        break\n",
    "\n",
    "    driver.get(profile)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        current_pos = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[5]/div[3]/div/div/div[2]/div/div/main/section[1]/div[2]/div[2]/div[1]/div[2]\").text\n",
    "        current_comp = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[5]/div[3]/div/div/div[2]/div/div/main/section[1]/div[2]/div[2]/ul/li/button/span/div\").text\n",
    "        current_location = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[5]/div[3]/div/div/div[2]/div/div/main/section[1]/div[2]/div[2]/div[2]/span[1]\").text\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    get_url = driver.current_url\n",
    "    new_url = get_url+\"/details/experience/\"\n",
    "    driver.get(new_url)\n",
    "    time.sleep(10)\n",
    "    j = 1\n",
    "    experiences = []\n",
    "    while True:\n",
    "        try:\n",
    "            position = driver.find_element_by_xpath(\n",
    "                \"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[\"+str(j)+\"]/div/div/div[2]/div[1]/div[1]/div/span/span[1]\").text\n",
    "            comp_name = driver.find_element_by_xpath(\n",
    "                \"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[\"+str(j)+\"]/div/div/div[2]/div[1]/div[1]/span[1]/span[1]\").text\n",
    "            exp = driver.find_element_by_xpath(\n",
    "                \"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[\"+str(j)+\"]/div/div/div[2]/div[1]/div[1]/span[2]/span[1]\").text\n",
    "            experiences.append({'Position': position, 'Company': comp_name, 'Experience': exp})\n",
    "            j += 1\n",
    "        except NoSuchElementException:\n",
    "            print(\"No such element found at \"+str(j)+\"th position\")\n",
    "            break\n",
    "    profile_data[profile] = experiences\n",
    "    i += 1\n",
    "\n",
    "# Save data to CSV file\n",
    "with open('output.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Profile\", \"Position\", \"Company\", \"Experience\"])\n",
    "    for profile, experiences in profile_data.items():\n",
    "        flattened_experiences = [dict(exp, Profile=profile)\n",
    "                                 for exp in experiences]\n",
    "        for exp in flattened_experiences:\n",
    "            writer.writerow(exp.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\TCD\\Data Analytics\\Project\\chromedriver\\chromedriver.exe\n",
      "No such element found at 7th position\n",
      "No such element found at 1th position\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22952\\2099189927.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;31m# Convert profile_data dictionary to a DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;31m# Save DataFrame to CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         ]\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_driver = os.getcwd()+\"\\\\chromedriver\\\\chromedriver.exe\"\n",
    "print(chrome_driver)\n",
    "# Path to your chrome profile\n",
    "chrome_options.add_argument(\n",
    "    \"user-data-dir=C:\\\\Users\\\\Arnav\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")\n",
    "# chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(\n",
    "    options=chrome_options, executable_path=chrome_driver)\n",
    "driver.maximize_window()\n",
    "\n",
    "profiles = reaction_df['Profile']\n",
    "profile_data = {}\n",
    "i=1\n",
    "for profile in profiles:\n",
    "    if i > 2:\n",
    "        break\n",
    "\n",
    "    driver.get(profile)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        current_pos = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[5]/div[3]/div/div/div[2]/div/div/main/section[1]/div[2]/div[2]/div[1]/div[2]\").text\n",
    "        current_comp = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[5]/div[3]/div/div/div[2]/div/div/main/section[1]/div[2]/div[2]/ul/li/button/span/div\").text\n",
    "        current_location = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[5]/div[3]/div/div/div[2]/div/div/main/section[1]/div[2]/div[2]/div[2]/span[1]\").text\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    get_url = driver.current_url\n",
    "    new_url = get_url+\"/details/experience/\"\n",
    "    driver.get(new_url)\n",
    "    time.sleep(10)\n",
    "    j = 1\n",
    "    experiences = []\n",
    "    while True:\n",
    "        try:\n",
    "            position = driver.find_element_by_xpath(\n",
    "                \"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[\"+str(j)+\"]/div/div/div[2]/div[1]/div[1]/div/span/span[1]\").text\n",
    "            comp_name = driver.find_element_by_xpath(\n",
    "                \"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[\"+str(j)+\"]/div/div/div[2]/div[1]/div[1]/span[1]/span[1]\").text\n",
    "            exp = driver.find_element_by_xpath(\n",
    "                \"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[\"+str(j)+\"]/div/div/div[2]/div[1]/div[1]/span[2]/span[1]\").text\n",
    "            experiences.append({'Position': position, 'Company': comp_name, 'Experience': exp,\n",
    "                                \"Current Position\": current_pos, \"Current Company\": current_comp, \"Current Location\": current_location})\n",
    "            j += 1\n",
    "        except NoSuchElementException:\n",
    "            print(\"No such element found at \"+str(j)+\"th position\")\n",
    "            break\n",
    "    profile_data[profile] = experiences\n",
    "    i += 1\n",
    "\n",
    "# Convert profile_data dictionary to a DataFrame\n",
    "df = pd.DataFrame(profile_data)\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv('profile_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://www.linkedin.com/in/ACoAABPhLisBO84-X75h2dpsHPXUuuYt50uvBZc': [{'Position': 'Rotating Equipment Engineer',\n",
       "   'Company': 'Schlumberger · Full-time',\n",
       "   'Experience': 'Aug 2022 - Present · 10 mos',\n",
       "   'Current Position': 'Schlumberger- Rotating Equipment Engineer',\n",
       "   'Current Company': 'Schlumberger',\n",
       "   'Current Location': 'Coimbatore, Tamil Nadu, India'},\n",
       "  {'Position': 'Rotating Equipment Engineer',\n",
       "   'Company': 'L & T Chiyoda Ltd · Full-time',\n",
       "   'Experience': 'Feb 2018 - Jul 2022 · 4 yrs 6 mos',\n",
       "   'Current Position': 'Schlumberger- Rotating Equipment Engineer',\n",
       "   'Current Company': 'Schlumberger',\n",
       "   'Current Location': 'Coimbatore, Tamil Nadu, India'},\n",
       "  {'Position': 'Mechanical Engineer',\n",
       "   'Company': 'Venus engineering and consultancy · Full-time',\n",
       "   'Experience': 'Aug 2016 - Jan 2018 · 1 yr 6 mos',\n",
       "   'Current Position': 'Schlumberger- Rotating Equipment Engineer',\n",
       "   'Current Company': 'Schlumberger',\n",
       "   'Current Location': 'Coimbatore, Tamil Nadu, India'},\n",
       "  {'Position': 'Rotating Equipment Engineer',\n",
       "   'Company': 'Fluor Daniel India Private Limited',\n",
       "   'Experience': 'Feb 2015 - May 2016 · 1 yr 4 mos',\n",
       "   'Current Position': 'Schlumberger- Rotating Equipment Engineer',\n",
       "   'Current Company': 'Schlumberger',\n",
       "   'Current Location': 'Coimbatore, Tamil Nadu, India'},\n",
       "  {'Position': 'Rotating Equipment Engineer',\n",
       "   'Company': 'GS E&C',\n",
       "   'Experience': 'Feb 2014 - Feb 2015 · 1 yr 1 mo',\n",
       "   'Current Position': 'Schlumberger- Rotating Equipment Engineer',\n",
       "   'Current Company': 'Schlumberger',\n",
       "   'Current Location': 'Coimbatore, Tamil Nadu, India'},\n",
       "  {'Position': 'Rotating Equipment Engineer',\n",
       "   'Company': 'IOTL',\n",
       "   'Experience': 'Aug 2011 - Dec 2013 · 2 yrs 5 mos',\n",
       "   'Current Position': 'Schlumberger- Rotating Equipment Engineer',\n",
       "   'Current Company': 'Schlumberger',\n",
       "   'Current Location': 'Coimbatore, Tamil Nadu, India'}],\n",
       " 'https://www.linkedin.com/in/ACoAAAANe6cBu5F-0id6dUg1fHFP021ytEp5Abc': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\TCD\\Data Analytics\\Project\\chromedriver\\chromedriver.exe\n",
      "No such element found at 7th position\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import os\n",
    "import time\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_driver = os.getcwd()+\"\\\\chromedriver\\\\chromedriver.exe\"\n",
    "print(chrome_driver)\n",
    "# Path to your chrome profile\n",
    "chrome_options.add_argument(\n",
    "    \"user-data-dir=C:\\\\Users\\\\Arnav\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")\n",
    "# chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(\n",
    "    options=chrome_options, executable_path=chrome_driver)\n",
    "driver.maximize_window()\n",
    "\n",
    "profiles = reaction_df['Profile']\n",
    "profile_data = {}\n",
    "i=1\n",
    "current_comp=\"\"\n",
    "current_location=\"\"\n",
    "current_pos=\"\"\n",
    "for profile in profiles:\n",
    "    if i > 1:\n",
    "        break\n",
    "\n",
    "    driver.get(profile)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        current_pos = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[5]/div[3]/div/div/div[2]/div/div/main/section[1]/div[2]/div[2]/div[1]/div[2]\").text\n",
    "        current_comp = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[5]/div[3]/div/div/div[2]/div/div/main/section[1]/div[2]/div[2]/ul/li/button/span/div\").text\n",
    "        current_location = driver.find_element_by_xpath(\n",
    "            \"/html/body/div[5]/div[3]/div/div/div[2]/div/div/main/section[1]/div[2]/div[2]/div[2]/span[1]\").text\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    get_url = driver.current_url\n",
    "    new_url = get_url+\"/details/experience/\"\n",
    "    driver.get(new_url)\n",
    "    time.sleep(10)\n",
    "    j = 1\n",
    "    experiences = []\n",
    "    while True:\n",
    "        try:\n",
    "            position = driver.find_element_by_xpath(\n",
    "                \"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[\"+str(j)+\"]/div/div/div[2]/div[1]/div[1]/div/span/span[1]\").text\n",
    "            comp_name = driver.find_element_by_xpath(\n",
    "                \"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[\"+str(j)+\"]/div/div/div[2]/div[1]/div[1]/span[1]/span[1]\").text\n",
    "            exp = driver.find_element_by_xpath(\n",
    "                \"/html/body/div[6]/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[\"+str(j)+\"]/div/div/div[2]/div[1]/div[1]/span[2]/span[1]\").text\n",
    "            experiences.append(\n",
    "                {'Position': position, 'Company': comp_name, 'Experience': exp})\n",
    "            j += 1\n",
    "        except NoSuchElementException:\n",
    "            print(\"No such element found at \"+str(j)+\"th position\")\n",
    "            break\n",
    "    profile_data[profile] = {'Experiences': experiences,\n",
    "                         'Current Position': current_pos,\n",
    "                         'Current Company': current_comp,\n",
    "                         'Current Location': current_location}\n",
    "\n",
    "    i += 1\n",
    "\n",
    "# Save data to CSV file\n",
    "with open('output.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Profile\", \"Position\", \"Company\", \"Experience\", \"Current_Position\", \"Current_Company\", \"Current_Location\"])\n",
    "    for profile, experiences in profile_data.items():\n",
    "        flattened_data = [{'Profile': profile,\n",
    "                            'Position': exp['Position'],\n",
    "                            'Company': exp['Company'],\n",
    "                            'Experience': exp['Experience'],\n",
    "                            'Current Position': experiences['Current Position'],\n",
    "                            'Current Company': experiences['Current Company'],\n",
    "                            'Current Location': experiences['Current Location']}\n",
    "                            for exp in experiences['Experiences']]\n",
    "\n",
    "        for data in flattened_data:\n",
    "            writer.writerow(data.values())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
